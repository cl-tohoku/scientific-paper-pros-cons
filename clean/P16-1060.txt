Which	O
Coreference	O
Evaluation	O
Metric	O
Do	O
You	O
Trust O
? O
A	O
Proposal	O
for	O
a	O
Link-based	O
Entity	O
Aware	O
Metric	O

There	O
exists	O
a	B-NEU
variety	I-NEU
of	I-NEU
models	I-NEU
(	O
e.g.	O
pairwise	B-NEU
, O
entity-based	B-NEU
, O
and	O
ranking	B-NEU
and	O
feature	O
sets	O
(	O
e.g. O
string	O
match	O
,	O
lexical	O
,	O
syntactic	O
,	O
and	O
semantic	O
)	O
to	O
be	O
used	O
in	O
coreference	O
resolution	O
.	O

There	O
is	O
no	O
known	O
formal	O
way	O
to	O
prove	O
which	O
coreference	B-NEU
model	I-NEU
is	O
superior	O
to	O
the	O
others	O
and	O
which	O
set	O
of	O
features	O
is	O
more	O
beneficial/less	O
useful	O
in	O
coreference	O
resolution	O
.	O

The	O
only	O
way	O
to	O
compare	O
different	O
models	O
,	O
features	O
or	O
implementations	O
of	O
coreference	B-NEU
resolvers	I-NEU
is	O
to	O
compare	O
the	O
values	O
of	O
the	O
existing	O
coreference	O
resolution	O
evaluation	O
metrics	O
.	O

By	O
comparing	O
the	O
evaluation	O
scores	O
,	O
we	O
determine	O
which	O
system	O
performs	O
best	O
,	O
which	O
model	O
suits	O
coreference	O
resolution	O
better	O
,	O
and	O
which	O
feature O
set	O
is	O
useful	O
for	O
improving	O
the	O
recall	O
or	O
precision	O
of	O
a	O
coreference	O
resolver	O
.	O

Therefore	O
,	O
evaluation	O
metrics	O
play	O
an	O
important	O
role	O
in	O
the	O
advancement	O
of	O
the	O
underlying	O
technology	O
.	O

It	O
is	O
imperative	O
for	O
the	O
evaluation	O
metrics	O
to	O
be	O
reliable	O
.	O

However	O
,	O
it	O
is	O
not	O
a	O
trivial	O
task	O
to	O
score	O
output	O
entities	O
with	O
various	O
kinds	O
of	O
coreference	O
errors	O
.	O

Several	O
evaluation	O
metrics	O
have	O
been	O
introduced	O
for	O
coreference	O
resolution	O
(	O
Vilain	O
et	O
al.	O
,	O
1995 O
; O
Bagga	O
and	O
Baldwin	O
,	O
1998	O
;	O
Luo	O
,	O
2005	O
;	O
Recasens	O
and	O
Hovy	O
,	O
2011	O
;	O
Tuggener	O
,	O
2014	O
)	O
.	O

Metrics	O
that	O
are	O
being	O
used	O
widely	O
are	O
MUC	O
(	O
Vilain	O
et	O
al. O
, O
1995	O
)	O
,	O
B	O
3	O
(	O
Bagga	O
and	O
Baldwin	O
,	O
1998	O
)	O
,	O
CEAF O
( O
Luo	O
,	O
2005	O
)	O
,	O
and	O
BLANC	O
(	O
Recasens	O
and	O
Hovy O
, O
2011	O
)	O
.	O

There	O
are	O
known	O
flaws	O
for	O
each	O
of	O
these	O
metrics	O
.	O

Besides	O
,	O
the	O
agreement	O
between	O
all	O
these	O
metrics	O
is	O
relatively	O
low	O
(	O
Holen	O
,	O
2013	O
)	O
,	O
and	O
it	O
is	O
not	O
clear	O
which	O
metric	O
is	O
the	O
most	O
reliable	O
.	O

The	O
CoNLL-2011/2012	O
shared	O
tasks	O
(	O
Pradhan	O
et	O
al. O
, O
2011	O
;	O
Pradhan	O
et	O
al.	O
,	O
2012	O
)	O
ranked	O
participating	B-NEU
systems	I-NEU
using	O
an	O
average	O
of	O
three	O
metrics	O
,	O
i.e. O
MUC	O
,	O
B	O
3	O
,	O
and	O
CEAF	O
,	O
following	O
a	O
proposal	O
by O
( O
Denis	O
and	O
Baldridge	O
,	O
2009a	O
)	O
.	O

Averaging	O
three	O
unreliable	O
scores	O
does	O
not	O
result	O
in	O
a	O
reliable	O
one	O
.	O

Besides	O
,	O
when	O
an	O
average	O
score	O
is	O
used	O
for	O
comparisons	O
,	O
it	O
is	O
not	O
possible	O
to	O
analyse	O
recall	O
and	O
precision	O
to	O
determine	O
which	O
output	O
is	O
more	O
precise	O
and	O
which	O
one	O
covers	O
more	O
coreference	O
information	O
.	O

This	O
is	O
indeed	O
a	O
requirement	O
for	O
coreference	B-NEU
resolvers	I-NEU
to	O
be	O
used	O
in	O
end-tasks	O
.	O

Therefore O
, O
averaging	O
individual	O
metrics	O
is	O
nothing	O
but	O
a	O
compromise	O
.	O

As	O
mentioned	O
by	O
Luo	O
(	O
2005	O
)	O
,	O
interpretability	O
and	O
discriminative	O
power	O
are	O
two	O
basic	O
requirements	O
for	O
a	O
reasonable	O
evaluation	O
metric	O
.	O

In	O
regard	O
to	O
the	O
interpretability	O
requirement	O
a	O
high	O
score	O
should	O
indicate	O
that	O
the	O
vast	O
majority	O
of	O
coreference	O
relations	O
and	O
entities	O
are	O
detected	O
correctly	O
.	O

Similarly	O
,	O
a	B-NEU
system	I-NEU
that	O
resolves	O
none	O
of	O
the	O
coreference	O
relations	O
or	O
entities	O
should	O
get	O
a	O
zero	O
score	O
.	O

An	O
evaluation	O
metric	O
should	O
also	O
be	O
discriminative	O
.	O

It	O
should	O
be	O
able	O
to	O
discriminate	O
between	O
good	O
and	O
bad	O
coreference	O
decisions	O
.	O

In	O
this	O
paper	O
,	O
we	O
report	O
on	O
a	O
drawback	O
for	O
B	O
3	O
,	O
CEAF	O
,	O
and	O
BLANC	O
which	O
violates	O
the	O
interpretability	O
requirement	O
.	O

We	O
also	O
show	O
that	O
this	O
flaw	O
invalidates	O
the	O
recall/precision	O
analysis	O
of	O
coreference	O
outputs	O
based	O
on	O
these	O
three	O
metrics	O
.	O

We	O
then	O
review	O
the	O
current	O
evaluation	O
metrics	O
with	O
their	O
known	O
flaws	O
to	O
explain	O
why	O
we	O
cannot	O
trust	O
them	O
and	O
need	O
a	O
new	O
reliable	O
one	O
.	O

Finally	O
,	O
we	O
propose	O
LEA O
, O
a	O
Link-based	O
Entity	O
Aware	O
evaluation	O
metric	O
that	O
is	O
designed	O
to	O
overcome	O
problems	O
of	O
the	O
existing	O
metrics	O
.	O

We	O
have	O
begun	O
the	O
process	O
of	O
integrating	O
the	O
LEA	O
metric	O
in	O
the	O
official	O
CoNLL	O
scorer	O
so	O
as	O
to	O
continue	O
the	O
progress	O
made	O
in	O
recent	O
years	O
to	O
produce	O
replicable	O
evaluation	O
metrics	O
.	O

In	O
order	O
to	O
use	O
the	O
LEA	O
metric	O
,	O
there	O
is	O
no	O
additional	O
requirement	O
than	O
that	O
of	O
the	O
CoNLL	O
scorer	O
v8.01	O
.	O
