Learning	O
Structured	O
Perceptrons	O
for	O
Coreference	O
Resolution	O
with	O
Latent	B-NEU
Antecedents	I-NEU
and	O
Non-local	B-NEU
Features	I-NEU

This	O
paper	O
studies	O
and	O
extends	O
previous	O
work	O
using	O
the	B-NEU
structured	I-NEU
perceptron	I-NEU
(	O
Collins	O
,	O
2002	O
)	O
for	O
complex	O
NLP	O
tasks	O
.	O

We	O
show	O
that	O
for	O
the	O
task	O
of	O
coreference	O
resolution	O
the	O
straightforward	O
combination	O
of	O
beam	O
search	O
and	O
early	O
update	O
(	O
Collins	O
and	O
Roark	O
,	O
2004	O
)	O
falls	O
short	O
of	O
more	O
limited	O
feature	O
sets	O
that	O
allow	O
for	O
exact	O
search	O
.	O

This	O
contrasts	O
with	O
previous	O
work	O
on	O
,	O
e.g.	O
,	O
syntactic	O
parsing O
( O
Collins	O
and	O
Roark	O
,	O
2004	O
;	O
Huang	O
,	O
2008	O
;	O
Zhang	O
and	O
Clark	O
,	O
2008	O
)	O
and	O
linearization	O
(	O
Bohnet	O
et	O
al.	O
,	O
2011	O
)	O
,	O
and	O
even	O
simpler	O
structured	O
prediction	O
problems	O
,	O
where	O
early	O
updates	O
are	O
not	O
even	O
necessary	O
,	O
such	O
as	O
part-of-speech	O
tagging	O
(	O
Collins O
, O
2002	O
)	O
and	O
named	O
entity	O
recognition	O
(	O
Ratinov	O
and	O
Roth	O
,	O
2009	O
)	O
.	O

The	O
main	O
reason	O
why	O
early	O
updates	O
underperform	O
in	O
our	O
setting	O
is	O
that	O
the	O
task	O
is	O
too	O
difficult	O
and	O
that	O
the	O
learning	O
algorithm	O
is	O
not	O
able	O
to	O
profit	O
from	O
all	O
training	O
data	O
.	O

Put	O
another	O
way	O
,	O
early	O
updates	O
happen	O
too	O
early	O
,	O
and	O
the	O
learning	O
algorithm	O
rarely	O
reaches	O
the	O
end	O
of	O
the	O
instances	O
as	O
it	O
halts O
, O
updates	O
,	O
and	O
moves	O
on	O
to	O
the	O
next	O
instance	O
.	O

An	O
alternative	O
would	O
be	O
to	O
continue	O
decoding	O
the	O
same	O
instance	O
after	O
the	O
early	O
updates O
, O
which	O
is	O
equivalent	O
to	O
Learning	B-NEU
as	I-NEU
Search	I-NEU
Optimization	I-NEU
(	O
LaSO	O
;	O
Daumé	O
III	O
and	O
Marcu	O
(	O
2005b	O
)	O
)	O
.	O

The	O
learning	O
task	O
we	O
are	O
tackling	O
is	O
however	O
further	O
complicated	O
since	O
the	O
target	O
structure	O
is	O
under-determined	O
by	O
the	O
gold	O
standard	O
annotation	O
.	O

Coreferent	O
mentions	O
in	O
a	O
document	O
are	O
usually	O
annotated	O
as	O
sets	O
of	O
mentions	O
,	O
where	O
all	O
mentions	O
in	O
a	O
set	O
are	O
coreferent	O
.	O

We	O
adopt	O
the	O
recently	O
popularized	O
approach	O
of	O
inducing	O
a	B-NEU
latent	I-NEU
structure	I-NEU
within	O
these	O
sets	O
(	O
Fernandes	O
et	O
al.	O
,	O
2012	O
;	O
Chang	O
et	O
al.	O
,	O
2013	O
;	O
Durrett	O
and	O
Klein	O
,	O
2013	O
)	O
.	O

This	B-POS
approach	I-POS
provides	O
a	O
powerful	O
boost	O
to	O
the	O
performance	O
of	O
coreference	O
resolvers	O
,	O
but	O
we	O
find	O
that	O
it	O
does	O
not	O
combine	O
well	O
with	O
the	B-NEU
LaSO	I-NEU
learning	I-NEU
strategy I-NEU
.	O

We	O
therefore	O
propose	O
a	O
modification	O
to	O
LaSO	O
,	O
which	O
delays	O
updates	O
until	O
after	O
each	O
instance	O
.	O

The	O
combination	O
of	O
this	O
modification	O
with	O
non-local	O
features	O
leads	O
to	O
further	O
improvements	O
in	O
the	O
clustering	O
accuracy	O
,	O
as	O
we	O
show	O
in	O
evaluation	O
results	O
on	O
all	O
languages	O
from	O
the	O
CoNLL	O
2012	O
Shared	O
Task	O
–Arabic	O
,	O
Chinese	O
,	O
and	O
English	O
.	O

We	O
obtain	O
the	O
best	O
results	O
to	O
date	O
on	O
these	O
data	O
sets O
.	O
