A	O
Practical	O
Perspective	O
on	O
Latent	B-NEU
Structured	I-NEU
Prediction	I-NEU
for	O
Coreference	O
Resolution	O

Recent	B-NEU
research	I-NEU
on	O
CR	O
has	O
shown	O
effective	O
applications	O
of	O
structured	B-NEU
prediction	I-NEU
e.g.	O
,	O
the	B-POS
latent	I-POS
structured	I-POS
perceptron	I-POS
(	O
LSP	O
)	O
by	O
Fernandes	O
et	O
al. O
( O
2014	O
)	O
obtained	O
the	O
top	O
rank	O
in	O
the	O
CoNLL-2012	O
Shared	O
Task	O
(	O
Pradhan	O
et	O
al.	O
,	O
2012	O
)	O
.	O

There	O
has	O
been	O
an	O
exploration	O
of	O
LSP	B-NEU
variants	O
(	O
Chang	O
et	O
al.	O
,	O
2011;Björkelund	O
and	O
Kuhn	O
,	O
2014	O
;	O
Lassalle	O
and	O
Denis	O
,	O
2015	O
)	O
,	O
and	O
also	O
of	O
SGD-like	B-NEU
methods	I-NEU
(	O
Chang	O
et	O
al.	O
,	O
2013	O
;	O
Peng	O
et	O
al.	O
,	O
2015	O
;	O
Kummerfeld	O
et	O
al. O
, O
2015	O
)	O
.	O

Surprisingly	O
,	O
no	O
study	O
was	O
devoted	O
to	O
LSSVM	B-POS
by	O
Yu	O
and	O
Joachims	O
(	O
2009	O
)	O
,	O
which	O
offers	O
theoretical	O
guarantees	O
on	O
reducing	O
the	O
error	O
upper-bound	O
.	O

The	O
major	O
advantage	O
of	O
such	O
a	O
theory	O
is	O
the	O
possibility	O
to	O
stop	O
the	O
optimization	O
process	O
,	O
carried	O
out	O
using	O
the	B-POS
Concave-Convex	I-POS
Procedure	I-POS
(	O
CCCP	O
)	O
by	O
Yuille	O
and	O
Rangarajan	O
(	O
2003	O
)	O
,	O
when	O
the	O
approximation	O
to	O
the	O
optimum	O
is	O
close	O
as	O
much	O
as	O
we	O
want	O
.	O

In	O
contrast	O
,	O
the	O
gradient	O
descent	O
operated	O
by	O
perceptron-like	B-NEU
algorithms	I-NEU
does	O
not	O
allow	O
us	O
to	O
estimate	O
how	O
much	O
our	O
solution	O
is	O
far	O
away	O
from	O
the	O
optimum	O
.	O

In	O
other	O
words	O
,	O
we	O
do	O
not	O
know	O
at	O
which	O
epoch	O
our	B-NEU
algorithm	I-NEU
should	O
stop	O
.	O

Thus	O
,	O
LSSVM	B-POS
holds	O
an	O
important	O
advantage	O
over	O
online	B-NEU
methods	I-NEU
. O

In	O
this	O
paper	O
,	O
we	O
empirically	O
compare	O
LSSVM	B-NEU
with	O
two	B-NEU
online	I-NEU
learning	I-NEU
algorithms	I-NEU
, O
LSP	B-NEU
and	O
LSPA	B-NEU
(	O
a	O
structured	O
passive-aggressive	O
(	O
PA	O
)	O
algorithm	O
(	O
Crammer	O
et	O
al.	O
,	O
2006	O
)	O
that	O
we	O
extended	O
with	O
latent	O
variables	O
)	O
using	O
the	O
exact	O
setting	O
of	O
the	O
CoNLL-2012	O
dataset	O
.	O

This	O
preserves	O
comparability	O
with	O
the	O
work	O
in	O
CR	O
.	O

For	O
example	O
,	O
we	O
use	O
the	O
latest	O
version	O
of	O
the	O
MELA	O
scorer	O
.	O

It	O
should	O
be	O
noted	O
that	O
implementing	O
a	O
sound	O
comparison	O
was	O
rather	O
complex	O
as	O
it	O
required	O
testing	O
all	O
the	O
algorithms	O
in	O
the	O
same	O
conditions	O
and	O
optimally	O
setting	O
their	O
parameters	O
.	O

In	O
particular	O
,	O
LSSVM	B-NEU
and	O
LSP	B-NEU
adopt	O
different	O
graph	B-NEU
models	I-NEU
and	O
use	O
different	O
methods	O
to	O
extract	O
spanning	O
trees	O
from	O
a	O
document	O
graph	O
,	O
namely	O
,	O
Kruskal’s O
( O
Kruskal	O
,	O
1956	O
)	O
and	O
Edmonds’	O
(	O
Chu	O
and	O
Liu O
, O
1965	O
;	O
Edmonds	O
,	O
1967	O
)	O
.	O

Although	O
both	O
extract	O
optimal	O
spanning	O
trees	O
,	O
they	O
provide	O
different	O
solutions	O
,	O
which	O
critically	O
impact	O
on	O
accuracy	O
and	O
efficiency	O
.	O

The	O
latter	O
is	O
problematic	O
as	O
LSSVM	B-NEG
requires	O
too	O
long	O
time	O
for	O
convergence	O
on	O
the	O
large	O
CoNLL	O
dataset	O
.	O

To	O
tackle	O
this	O
issue	O
,	O
we	O
applied	O
two	O
kinds	O
of	O
efficiency	O
boost:	O
feature	O
and	O
mention	O
pair	O
selection	O
.	O

Feature	O
selection	O
was	O
rather	O
challenging	O
as	O
the	O
CR	O
feature	O
space	O
is	O
different	O
from	O
a	O
standard	O
text	O
categorization	O
setting	O
.	O

We	O
could	O
not	O
apply	O
a	O
filtering	O
threshold	O
on	O
simple	O
and	O
effective	O
statistics	O
such	O
as	O
document	O
frequency	O
since	O
almost	O
all	O
the	O
features	O
appear	O
in	O
many	O
documents	O
.	O

For	O
solving	O
this	O
problem	O
,	O
we	O
explored	O
the	O
use	O
of	O
efficient	O
binary	O
SVMs	B-NEU
for	O
computing	O
feature	O
weights	O
,	O
which	O
we	O
used	O
forour	O
selection	O
.	O

Additionally	O
,	O
we	O
also	O
provided	O
a	O
parallelized	O
version	O
of	O
LSSVM	B-NEU
to	O
afford	O
the	O
computation	O
requirement	O
of	O
the	O
full	O
CoNLL	O
dataset	O
.	O

The	O
results	O
of	O
our	B-NEU
study	I-NEU
show	O
that	O
LSSVM	B-POS
can	O
be	O
trained	O
on	O
large	O
data	O
and	O
achieve	O
the	O
state	O
of	O
the	O
art	O
of	O
online	B-NEU
methods	I-NEU
However	O
,	O
the	O
latter	O
using	O
optimal	O
parameters	O
can	O
even	O
surpass	O
its	O
accuracy	O
and	O
outperform	O
the	O
current	O
state	O
of	O
the	O
art	O
of	O
LSP	B-NEU
by	O
2	O
points	O
.	O

Finally	O
,	O
our	B-POS
feature	I-POS
selection	I-POS
algorithm	I-POS
is	O
rather	O
efficient	O
and	O
effective	O
.	O
