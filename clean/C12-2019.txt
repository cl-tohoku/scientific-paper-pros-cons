Chinese	O
Noun	O
Phrase	O
Coreference	O
Resolution O
: O
Insights	O
into	O
the	O
State	O
of	O
the	O
Art	O

Coreference	O
resolution	O
is	O
the	O
task	O
of	O
determining	O
which	O
noun	O
phrases	O
(	O
NPs	O
)	O
in	O
a	O
text	O
refer	O
to	O
the	O
same	O
real-world	O
entity	O
.	O

Compared	O
to	O
the	O
amount	O
of	O
research	O
on	O
English	O
coreference	O
resolution O
, O
relatively	O
little	O
work	O
has	O
been	O
done	O
on	O
Chinese	O
coreference	O
resolution	O
.	O

Worse	O
still	O
,	O
it	O
has	O
been	O
difficult	O
to	O
determine	O
the	O
state	O
of	O
the	O
art	O
in	O
Chinese	O
coreference	O
resolution	O
.	O

The	O
reason	O
can	O
be	O
attributed	O
in	O
part	O
to	O
the	O
lack	O
of	O
a	O
standard	O
evaluation	O
dataset O
:	O
while	O
recently	O
developed	O
Chinese	O
resolvers	O
are	O
typically	O
evaluated	O
on	O
the	O
ACE	O
datasets	O
,	O
different	O
researchers	O
have	O
used	O
different	O
splits	O
of	O
the	O
ACE	O
data	O
for	O
training	O
and	O
testing	O
,	O
making	O
performance	O
comparisons	O
difficult O
.	O

The	O
organizers	O
of	O
the	O
CoNLL-2012	O
shared	O
task	O
,	O
Modeling	O
Unrestricted	O
Multilingual	O
Coreference	O
in	O
OntoNotes	O
,	O
have	O
recently	O
addressed	O
this	O
issue	O
by	O
providing	O
free	O
access	O
to	O
the	O
training	O
and	O
test	O
sets	O
used	O
in	O
the	O
official	O
evaluation	O
(	O
Pradhan	O
et	O
al.	O
,	O
2012	O
)	O
.	O

Our	O
goal	O
in	O
this	O
paper	O
is	O
to	O
gain	O
a	O
better	O
understanding	O
of	O
the	O
state	O
of	O
the	O
art	O
in	O
Chinese	O
coreference	O
resolution O
by O
providing O
an	B-POS
extensive I-POS 
empirical I-POS
analysis	I-POS
of O
four O
Chinese O
resolver	O
,	O
which O
is O
ranked O
first	O
on	O
the	O
Chinese	O
subtask	O
of	O
the	O
CoNLL-2012	O
shared	O
task	O
.	O

Briefly	O
,	O
our	B-NEU
resolver	I-NEU
adopts	O
a	B-NEU
hybrid	I-NEU
rule-based/machine	I-NEU
learning	I-NEU
approach	I-NEU
to	O
coreference	O
resolution	O
,	O
extending	O
the	B-POS
successful	I-POS
rule-based	I-POS
multi-pass	I-POS
sieve	I-POS
approach	I-POS
(	O
Raghunathan	O
et	O
al.	O
,	O
2010	O
;	O
Lee	O
et	O
al.	O
,	O
2011	O
)	O
with	O
lexical	O
features	O
that	O
have	O
proven	O
useful	O
in	O
machine	B-NEU
learning	I-NEU
approaches	I-NEU
(	O
Rahman	O
and	O
Ng	O
,	O
2011a	O
,	O
2011b	O
)	O
.	O

Our	O
analysis	O
is	O
focused	O
on	O
four	O
issues	O
.	O

1. O
Mention	O
detection	O
.	O

Previous	B-NEU
work	I-NEU
has	O
shown	O
that	O
the	O
quality	O
of	O
the	O
extracted	O
mentions O
( O
i.e.	O
,	O
the	O
NPs	O
participating	O
in	O
a	O
coreference	O
chain	O
)	O
plays	O
an	O
important	O
role	O
in	O
the	O
performance	O
of	O
a	O
resolver	O
.	O

To	O
what	O
extent	O
is	O
the	O
performance	O
of	O
our	O
resolver	O
limited	O
by	O
the	O
recall	O
and	O
precision	O
of	O
our	B-NEU
mention	I-NEU
detector	I-NEU
? O

To	O
improve	O
the	O
precision	O
of	O
our	O
mention	O
detector	O
,	O
we	O
need	O
to	O
improve	O
its	O
mention	O
pruning	O
strategy	O
,	O
but	O
to	O
what	O
extent	O
is	O
its	O
precision	O
limited	O
by	O
our	O
current	O
mention	O
pruning	O
strategy O
?	O

To	O
improve	O
the	O
recall	O
of	O
our	O
mention	O
detector	O
,	O
we	O
need	O
to	O
improve	O
the	O
extraction	O
of	O
mentions	O
from	O
syntactic	B-NEU
parse	I-NEU
trees	I-NEU
but	O
to	O
what	O
extent	O
is	O
its	O
recall	O
limited	O
by	O
the	O
mention	O
extraction	O
strategy	O
versus	O
the	O
quality	O
of	O
the	O
syntactic	O
parses O
?	O

2.Preprocessing	O
.	O

After	O
mention	O
detection	O
,	O
we	O
need	O
to	O
compute	O
features	O
based	O
on	O
the	O
extracted	O
mentions	O
using	O
preprocessing	O
tools	O
such	O
as	O
syntactic	B-NEU
parsers	I-NEU
and	O
named	B-NEU
entity	I-NEU
(	I-NEU
NE	I-NEU
)	I-NEU
recognizers	I-NEU
. O

To	O
what	O
extent	O
is	O
the	O
performance	O
of	O
our	O
resolver	O
limited	O
by	O
the	O
correctness	O
of	O
the	O
output	O
produced	O
by	O
these	O
tools O
?	O

3.	O
The	B-NEU
coreference	I-NEU
algorithm	I-NEU
. O

To	O
better	O
understand	O
our	B-NEU
hybrid	I-NEU
approach	I-NEU
we	O
focus	O
on	O
three	O
questions	O
.	O

First	O
,	O
do	O
we	O
really	O
need	O
a	B-NEU
hybrid	I-NEU
approach	I-NEU
In	O
other	O
words	O
,	O
will	O
our	B-NEU
approach	I-NEU
work	O
equally	O
well	O
without	O
the	O
learning	O
component O
?	O

Second	O
,	O
how	O
much	O
does	O
each	O
sieve	O
in	O
the	B-NEU
multi-pass	I-NEU
sieve	I-NEU
approach	I-NEU
contribute	O
to	O
overall	O
performance O
?	O

Third	O
,	O
how	O
important	O
is	O
the	O
ordering	O
of	O
the	O
sieves	O
as	O
far	O
as	O
performance	O
is	O
concerned O
?	O

4. O
Comparison	O
with	O
classifier-based	B-NEU
approaches	I-NEU
. O

In	O
the	O
shared	O
task	O
,	O
our	B-POS
resolver	I-POS
outperformed	O
those	B-NEU
systems	I-NEU
that	O
adopted	O
the	B-NEU
popularly-used	I-NEU
mention-pair	I-NEU
(	I-NEU
MP	I-NEU
)	I-NEU
model	I-NEU
(	O
Soon	O
et	O
al. O
, O
2001	O
)	O
,	O
a	O
classifier	O
trained	O
to	O
determine	O
whether	O
two	O
given	O
NPs	O
are	O
coreferent	O
.	O

However O
, O
we	O
cannot	O
claim	O
that	O
our	B-NEG
coreference	I-NEG
algorithm	I-NEG
is	O
superior	O
to	O
the	B-NEU
MP	I-NEU
model	I-NEU
because	O
we	O
do	O
not	O
know	O
which	O
component(s)	O
of	O
our	O
resolver	O
(	O
e.g.	O
,	O
mention	O
detection	O
,	O
feature	O
computation O
, O
resolution	O
)	O
contributed	O
to	O
the	O
superiority	O
.	O

In	O
fact	O
,	O
much	B-NEG
of	I-NEG
the	I-NEG
previous	I-NEG
work	I-NEG
focuses	O
on	O
comparing	O
systems	O
rather	O
than	O
models/methods	O
.	O

We	O
determine	O
whether	O
our	B-NEU
resolution	I-NEU
method	I-NEU
is	O
better	O
than	O
the	B-NEU
MP	I-NEU
model	I-NEU
if	O
both	O
are	O
given	O
the	O
same	O
set	O
of	O
mentions	O
and	O
features	O
.	O
