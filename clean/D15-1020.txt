Cross-document	O
Event	O
Coreference	O
Resolution	O
based	O
on	O
Cross-media	O
Features	O

TV	O
news	O
is	O
the	O
medium	O
that	O
broadcasts	O
events O
,	O
stories	O
and	O
other	O
information	O
via	O
television	O
.	O

The	O
broadcast	O
is	O
conducted	O
in	O
programs	O
with	O
the	O
name	O
of	O
“ O
Newscast O
”	O
.	O

Typically	O
,	O
newscasts	O
require	O
one	O
or	O
several	O
anchors	O
who	O
are	O
introducing	O
stories	O
and	O
coordinating	O
transition	O
among	O
topics	O
,	O
reporters	O
or	O
journalists	O
who	O
are	O
presenting	O
events	O
in	O
the	O
fields	O
and	O
scenes	O
that	O
are	O
captured	O
by	O
cameramen	O
.	O

Similar	O
to	O
newspapers	O
,	O
the	O
same	O
stories	O
are	O
often	O
reported	O
by	O
multiple	O
newscast	O
agents	O
.	O

Moreover	O
,	O
in	O
order	O
to	O
increase	O
the	O
impact	O
on	O
audience	O
,	O
the	O
same	O
stories	O
and	O
events	O
are	O
reported	O
for	O
mutliple	O
times	O
.	O

TV	O
audience	O
passively	O
receives	O
redundant	O
information	O
,	O
and	O
often	O
has	O
difficulty	O
in	O
obtaining	O
clear	O
and	O
useful	O
digest	O
of	O
ongoing	O
events	O
.	O

These	O
properties	O
lead	O
to	O
needs	O
for	O
automatic	B-NEU
methods	I-NEU
to	O
cluster	O
information	O
and	O
remove	O
redundancy	O
.	O

We	O
propose	O
a	O
new	O
research	O
problem	O
of	O
event	O
coreference	O
resolution	O
across	O
multiple	O
news	O
videos	O
.	O

To	O
tackle	O
this	O
problem	O
,	O
a	O
good	O
starting	O
point	O
is	O
processing	O
the	O
Closed	O
Captions	O
(	O
CC	O
)	O
which	O
is	O
accompanying	O
videos	O
in	O
newcasts	O
.	O

The	O
CC	O
is	O
either	O
generated	O
by	O
automatic	B-NEU
speech	I-NEU
recognition	I-NEU
(	I-NEU
ASR	I-NEU
)	I-NEU
systems	I-NEU
or	O
transcribed	O
by	O
a	O
human	O
stenotype	O
operator	O
who	O
inputs	O
phonetics	O
which	O
are	O
instantly	O
and	O
automatically	O
translated	O
into	O
texts O
, O
where	O
events	O
can	O
be	O
extracted	O
.	O

There	O
exist	O
some	O
previous	O
event	O
coreference	O
resolution	O
work	O
such	O
as	O
(	O
Chen	O
and	O
Ji	O
,	O
2009b	O
;	O
Chen	O
et	O
al.	O
,	O
2009	O
;	O
Lee	O
et	O
al.	O
,	O
2012	O
;	O
Bejan	O
and	O
Harabagiu	O
,	O
2010	O
)	O
.	O

However O
, O
they	O
only	O
focused	O
on	O
formally	O
written	O
newswire	O
articles	O
and	O
utilized	O
textual	O
features	O
.	O

Such	B-NEG
approaches	I-NEG
do	O
not	O
perform	O
well	O
on	O
CC	O
due	O
to	O
(1) O
. O
the	O
propagated	O
errors	O
from	O
upper	O
stream	O
components	O
(	O
e.g.	O
,	O
automatic	O
speech/stenotype	O
recognition	O
and	O
event	O
extraction	O
)	O
;	O
(2) O
.	O
the	O
incompleteness	O
of	O
information	O
.	O

Different	O
from	O
written	O
news O
, O
newscasts	O
are	O
often	O
limited	O
in	O
time	O
due	O
to	O
fixed	O
TV	O
program	O
schedules	O
,	O
thus	O
,	O
anchors	O
and	O
journalists	O
are	O
trained	O
and	O
expected	O
to	O
organize	O
reports O
which	O
are	O
comprehensively	O
informative	O
with	O
complementary	O
visual	O
and	O
CC	O
descriptions	O
within	O
a	O
short	O
time	O
.	O

These	O
two	O
sides	O
have	O
minimal	O
overlapped	O
information	O
while	O
they	O
are	O
inter-dependent	O
.	O

For	O
example	O
,	O
anchors	O
and	O
reporters	O
introduce	O
the	O
background	O
story	O
which	O
are	O
not	O
presented	O
in	O
the	O
videos	O
,	O
and	O
thus	O
the	O
events	O
extracted	O
from	O
CC	O
often	O
lack	O
information	O
about	O
participants	O
.	O

For	O
example	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
,	O
these	O
two	O
Conflict.Attack	O
event	O
mentions	O
are	O
coreferential	O
.	O

However	O
,	O
in	O
the	O
first	O
event	O
mention	O
,	O
a	O
mistake	O
in	O
Closed	O
Caption	O
(	O
“ O
he	O
was	O
killed O
”	O
→	O
“ O
it	O
was	O
killed O
”	O
)	O
makes	O
event	O
extraction	O
and	O
text	B-NEG
based	I-NEG
coreference	I-NEG
systems	I-NEG
unable	O
to	O
detect	O
and	O
link	O
“　O
it O
” O
to	O
the	O
entity	O
of	O
“ O
Jordanian	O
pilot O
”	O
.	O

Fortunately O
, O
videos	O
often	O
illustrate	O
brief	O
descriptions	O
by	O
vivid	O
visual	O
contents	O
.	O

Moreover	O
,	O
diverse	O
anchors	O
,	O
reporters	O
and	O
TV	O
channels	O
tend	O
to	O
use	O
similar	O
or	O
identical	O
video	O
contents	O
to	O
describe	O
the	O
same	O
story O
, O
even	O
though	O
they	O
usually	O
use	O
different	O
words	O
and	O
phrases	O
.	O

Therefore	O
,	O
the	O
challenges	O
in	O
coreference	B-NEU
resolution	I-NEU
methods	I-NEU
based	O
on	O
text	O
information	O
can	O
be	O
addressed	O
by	O
incorporating	O
visual	O
similarity	O
.	O

In	O
this	O
example	O
,	O
the	O
visual	O
similarity	O
between	O
the	O
corresponding	O
video	O
frames	O
is	O
high	O
because	O
both	O
of	O
them	O
show	O
the	O
scene	O
of	O
the	O
Jordanian	O
pilot	O
.	O

Similar	B-NEU
work	I-NEU
such	O
as	O
(	O
Kong	O
et	O
al.	O
,	O
2014	O
)	O
,	O
(	O
Ramanathan	O
et	O
al.	O
,	O
2014	O
)	O
,	O
(	O
Motwani	O
and	O
Mooney O
, O
2012	O
)	O
and	O
(	O
Ramanathan	O
et	O
al.	O
,	O
2013	O
)	O
have	O
explored	O
methods	B-NEU
of	O
linking	O
visual	O
materials	O
with	O
texts	O
.	O

However	O
,	O
these	B-NEG
methods	I-NEG
mainly	O
focus	O
on	O
connecting	O
image	O
concepts	O
with	O
entities	O
in	O
text	O
mentions	O
;	O
and	O
some	O
of	O
them	O
do	O
not	O
clearly	O
distinguish	O
entity	O
and	O
event	O
in	O
the	O
documents	O
since	O
the	O
definition	O
of	O
visual	O
concepts	O
often	O
require	O
both	O
of	O
them	O
.	O

Moreover	O
,	O
the	B-NEU
aforementioned	I-NEU
work	I-NEU
mainly	O
focuses	O
on	O
improving	O
visual	O
contents	O
recognition	O
by	O
introducing	O
text	O
features	O
while	O
our	B-POS
work	I-POS
will	O
take	O
the	O
opposite	O
route	O
,	O
which	O
takes	O
advantage	O
of	O
visual	O
information	O
to	O
improve	O
event	O
coreference	O
resolution	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
jointly	O
incorporate	O
features	O
from	O
both	O
speech	O
(	O
textual	O
)	O
and	O
video	O
(	O
visual	O
)	O
channels	O
for	O
the	O
first	O
time	O
.	O

We	O
also	O
build	O
a	B-NEU
newscast	I-NEU
crawling	I-NEU
system	I-NEU
that	O
can	O
automatically	O
accumulate	O
video	O
records	O
and	O
transcribe	O
closed	O
captions	O
.	O

With	O
the	B-NEU
crawler	I-NEU
we	O
created	O
a	O
benchmark	O
dataset	O
which	O
is	O
fully	O
annotated	O
with	O
cross-document	O
coreferential	O
events	O
.	O
