Prune-and-Score O
:	O
Learning	O
for	O
Greedy	O
Coreference	O
Resolution	O

Coreference	O
resolution	O
is	O
the	O
task	O
of	O
clustering	O
a	O
set	O
of	O
mentions	O
in	O
the	O
text	O
such	O
that	O
all	O
mentions	O
in	O
the	O
same	O
cluster	O
refer	O
to	O
the	O
same	O
entity	O
.	O

It	O
is	O
one	O
of	O
the	O
first	O
stages	O
in	O
deep	O
language	O
understanding	O
and	O
has	O
a	O
big	O
potential	O
impact	O
on	O
the	O
rest	O
of	O
the	O
stages	O
.	O

Several	O
of	O
the	B-NEU
state-of-the-art	I-NEU
approaches	I-NEU
learn	O
a	O
scoring	O
function	O
defined	O
over	O
mention	B-NEU
pair	I-NEU
, O
cluster-mention	B-NEU
or	O
cluster-cluster	B-NEU
pair	I-NEU
to	O
guide	O
the	O
coreference	O
decision-making	O
process	O
(	O
Daumé	O
III	O
,	O
2006	O
;	O
Bengtson	O
and	O
Roth	O
,	O
2008	O
;	O
Rahman	O
and	O
Ng	O
,	O
2011b	O
;	O
Stoyanov	O
and	O
Eisner	O
,	O
2012	O
;	O
Chang	O
et	O
al.	O
,	O
2013	O
;	O
Durrett	O
et	O
al.	O
,	O
2013	O
;	O
Durrett	O
and	O
Klein O
, O
2013	O
)	O
.	O

One	O
common	O
and	O
persistent	O
problem	O
with	O
these	B-NEG
approaches	I-NEG
is	O
that	O
the	O
scoring	O
function	O
has	O
to	O
make	O
all	O
the	O
coreference	O
decisions	O
,	O
which	O
leads	O
to	O
a	O
highly	O
non-realizable	O
learning	O
problem	O
.	O

Inspired	O
by	O
the	O
recent	O
success	O
of	O
the	B-NEU
HC-Search	I-NEU
Framework	I-NEU
(	O
Doppa	O
et	O
al.	O
,	O
2014a	O
)	O
for	O
studying	O
a O
variety	O
of	O
structured	O
prediction	O
problems	O
(	O
Lam	O
et	O
al.	O
,	O
2013	O
;	O
Doppa	O
et	O
al.	O
,	O
2014c	O
)	O
,	O
we	O
study	O
a	B-NEU
novel	I-NEU
approach	I-NEU
for	O
search-based	B-NEU
coreference	I-NEU
resolution	I-NEU
called	O
Prune-and-Score	B-NEU
. O

HC-Search	B-POS
is	O
a	O
divide-and-conquer	O
solution	O
that	O
learns	O
multiple	O
components	O
with	O
pre-defined	O
roles	O
,	O
and	O
each	O
of	O
them	O
contribute	O
towards	O
the	O
overall	O
goal	O
by	O
making	O
the	O
role	O
of	O
the	O
other	O
components	O
easier	O
.	O

The	B-NEU
HC-Search	I-NEU
framework	I-NEU
operates	O
in	O
the	O
space	O
of	O
complete	O
outputs	O
,	O
and	O
relies	O
on	O
the	O
loss	O
function	O
which	O
is	O
only	O
defined	O
on	O
the	O
complete	O
outputs	O
to	O
drive	O
its	O
learning	O
.	O

Unfortunately	O
,	O
this	B-NEG
method	I-NEG
does	O
not	O
work	O
for	O
incremental	O
coreference	O
resolution	O
since	O
the	O
search	O
space	O
for	O
coreference	O
resolution	O
consists	O
of	O
partial	O
outputs	O
,	O
i.e.	O
,	O
a	O
set	O
of	O
mentions	O
only	O
some	O
of	O
which	O
have	O
been	O
clustered	O
so	O
far	O
.	O

We	O
develop	O
an	B-POS
alternative	I-POS
framework	I-POS
to	O
HC-Search	B-NEU
that	O
allows	O
us	O
to	O
effectively	O
learn	O
from	O
partial	O
output	O
spaces	O
and	O
apply	O
it	O
to	O
greedy	O
coreference	O
resolution	O
.	O

The	O
key	O
idea	O
of	O
our	B-NEU
work	I-NEU
is	O
to	O
address	O
the	O
problem	O
of	O
non-realizability	O
of	O
the	O
scoring	O
function	O
by	O
learning	O
two	O
different	O
functions O
:	O
1)	O
a	B-NEU
pruning	I-NEU
function	I-NEU
to	O
prune	O
most	O
of	O
the	O
bad	O
decisions	O
,	O
and	O
2)	O
a	B-NEU
scoring	I-NEU
function	I-NEU
to	O
pick	O
the	O
best	O
decision	O
among	O
those	O
that	O
are	O
remaining	O
.	O

Our	B-NEU
Prune-and-Score	I-NEU
approach	I-NEU
is	O
a	O
particular	O
instanti-ation	O
of	O
the	O
general	O
idea	O
of	O
learning	O
nearly-sound	O
constraints	O
for	O
pruning	O
,	O
and	O
leveraging	O
the	O
learned	O
constraints	O
to	O
learn	O
improved	O
heuristic	O
functions	O
for	O
guiding	O
the	O
search	O
.	O

The	O
pruning	O
constraints	O
can	O
take	O
different	O
forms	O
(	O
e.g.	O
,	O
classifiers	O
,	O
decision-list	O
,	O
or	O
ranking	O
functions	O
)	O
depending	O
on	O
the	B-NEU
search	I-NEU
architecture	I-NEU
. O

Therefore	O
,	O
other	B-NEU
coreference	I-NEU
resolution	I-NEU
systems	I-NEU
(	O
Chang	O
et	O
al.	O
,	O
2013	O
;	O
Durrett	O
and	O
Klein	O
,	O
2013	O
;	O
Björkelund	O
and	O
Kuhn	O
,	O
2014	O
)	O
can	O
also	O
benefit	O
from	O
this	B-POS
idea	I-POS
. O

While	O
our	B-NEU
basic	I-NEU
idea	I-NEU
of	O
two-level	O
selection	O
might	O
appear	O
similar	O
to	O
the	B-NEU
coarse-to-fine	I-NEU
inference	I-NEU
architectures	I-NEU
(	O
Felzenszwalb	O
and	O
McAllester	O
,	O
2007	O
;	O
Weiss	O
and	O
Taskar	O
,	O
2010	O
)	O
,	O
the	O
details	O
differ	O
significantly	O
.	O

Importantly	O
,	O
our	O
pruning	O
and	O
scoring	O
functions	O
operate	O
sequentially	O
at O
each	O
greedy	O
search	O
step	O
,	O
whereas	O
in	O
the	B-NEG
cascades	I-NEG
approach	I-NEG
the	O
second	O
level	O
function	O
makes	O
its	O
prediction	O
only	O
when	O
the	O
first	O
level	O
decision-making	O
is	O
done	O
.	O

Summary	O
of	O
Contributions	O
.	O

The	O
main	O
contributions	O
of	O
our	B-NEU
work	I-NEU
are	O
as	O
follows	O
.	O

First	O
,	O
we	O
motivate	O
and	O
introduce	O
the	B-NEU
Prune-and-Score	I-NEU
approach	I-NEU
to	O
search-based	B-NEU
coreference	I-NEU
resolution	I-NEU
. O

Second O
, O
we	O
identify	O
a	O
decomposition	O
of	O
the	O
overall	O
loss	O
of	O
the	B-NEU
Prune-and-Score	I-NEU
approach	I-NEU
into	O
the	O
pruning	O
loss	O
and	O
the	O
scoring	O
loss	O
,	O
and	O
reduce	O
the	O
problem	O
of	O
learning	O
these	O
two	O
functions	O
to	O
rank	O
learning O
, O
which	O
allows	O
us	O
to	O
leverage	O
powerful	O
and	O
efficient	O
off-the-shelf	O
rank	B-NEU
learners	I-NEU
. O

Third	O
,	O
we	O
evaluate	O
our	B-POS
approach	I-POS
on	O
OntoNotes	O
,	O
ACE	O
,	O
and	O
MUC	O
data	O
,	O
and	O
show	O
that	O
it	O
compares	O
favorably	O
to	O
several	B-NEU
state-of-the-art	I-NEU
approaches	I-NEU
as	O
well	O
as	O
a	B-NEU
greedy	I-NEU
search-based	I-NEU
approach	I-NEU
that	O
uses	O
a	O
single	O
scoring	O
function	O
.	O

The	O
remainder	O
of	O
the	O
paper	O
proceeds	O
as	O
follows	O
.	O

In	O
Section	O
2	O
,	O
we	O
dicuss	O
the	B-NEU
related	I-NEU
work	I-NEU
. O

We	O
introduce	O
our	O
problem	O
setup	O
in	O
Section	O
3	O
and	O
then	O
describe	O
our	B-NEU
Prune-and-Score	I-NEU
approach	I-NEU
in	O
Section	O
4 O
.	O

We	O
explain	O
our	B-NEU
approaches	I-NEU
for	O
learning	O
the	O
pruning	O
and	O
scoring	O
functions	O
in	O
Section	O
5 O
.	O

Section	O
6	O
presents	O
our	O
experimental	O
results	O
followed	O
by	O
the	O
conclusions	O
in	O
Section	O
7	O
.	O
