Latent	B-NEU
Trees	I-NEU
for	O
Coreference	O
Resolution	O

Mentions	O
are	O
textual	O
references	O
to	O
real-world	O
entities	O
or	O
events	O
.	O

In	O
a	O
given	O
document O
, O
mentions	O
that	O
refer	O
to	O
the	O
same	O
entity	O
are	O
called	O
coreferring	O
mentions	O
and	O
form	O
a	O
mention	O
cluster	O
.	O

Coreference	O
resolution	O
is	O
the	O
task	O
of	O
identifying	O
the	O
mention	O
clusters	O
in	O
a	O
document	O
and	O
has	O
been	O
a	O
core	O
research	O
topic	O
in	O
natural	O
language	O
processing	O
.	O

It	O
has	O
wide	O
applications	O
in	O
question	O
answering	O
,	O
machine	O
translation	O
,	O
automatic	O
summarization O
, O
and	O
information	O
extraction	O
.	O

Coreference	B-NEU
resolution	I-NEU
systems	I-NEU
have	O
been	O
evaluated	O
for O
several	O
decades	O
,	O
beginning	O
with	O
MUC-6	O
(	O
Sundheim	O
and	O
Grishman	O
1995	O
)	O
.	O

Following	O
those	O
evaluation	O
efforts	O
,	O
the	O
CoNLL-2011	O
Shared	O
Task	O
(	O
Pradhan	O
et	O
al.	O
2011	O
)	O
has	O
been	O
dedicated	O
to	O
the	O
modeling	O
of	O
unrestricted	O
coreference	O
resolution	O
for	O
English	O
text	O
.	O

The	O
CoNLL-2012	O
Shared	O
Task	O
(	O
Pradhan	O
et	O
al.	O
2012	O
)	O
extends	O
the	O
task	O
to	O
a	O
multilingual	O
scope O
, O
considering	O
three	O
languages O
:	O
Arabic	O
,	O
Chinese	O
,	O
and	O
English	O
.	O

A	O
singleton	O
is	O
a	O
mention	O
cluster	O
containing	O
exactly	O
one	O
mention	O
.	O

The	O
unrestricted	O
coreference	O
resolution	O
task	O
consists	O
of	O
identifying	O
the	O
non-singleton	O
mention	O
clusters	O
in	O
a	O
document	O
.	O

This	O
task	O
is	O
usually	O
split	O
into	O
three	O
subtasks O
:	O
mention	B-NEU
detection	I-NEU
mention	B-NEU
clustering	I-NEU
and	O
singleton	B-NEU
elimination	I-NEU
. O

In	O
Figure	O
1	O
,	O
we	O
present	O
an	O
illustrative	O
example	O
.	O

First	O
,	O
ten	O
mentions	O
are	O
detected	O
and	O
shown	O
in	O
bold	O
.	O

They	O
are	O
sequentially	O
tagged	O
with	O
the	O
numbers	O
1	O
,	O
2	O
,	O
.	O
.	O
.	O
,	O
10	O
.	O

Next	O
,	O
four	O
mention	O
clusters	O
are	O
identified	O
by	O
tagging	O
each	O
mention	O
with	O
one	O
of	O
the	O
tags	O
a	O
,	O
b	O
,	O
c	O
,	O
d	O
to	O
indicate	O
its	O
cluster	O
,	O
where	O
a	O
=	O
{	O
1	O
,	O
2	O
,	O
8	O
,	O
9	O
}	O
,	O
b	O
=	O
{	O
3	O
,	O
7	O
}	O
, O
c	O
=	O
{	O
4	O
,	O
5	O
,	O
6	O
}	O
,	O
d	O
=	O
{	O
10	O
}	O
are	O
the	O
four	O
mention	O
clusters	O
.	O

Finally	O
,	O
clusters	O
that	O
contain	O
only	O
one	O
mention	O
are	O
ignored	O
,	O
such	O
as	O
the	O
one	O
with	O
Iran	O
as	O
its	O
unique	O
mention	O
.	O

In	O
this	O
example	O
,	O
we	O
ignore	O
some	O
noun	O
phrases	O
in	O
the	O
mention	O
detection	O
subtask	O
to	O
simplify	O
the	O
illustration	O
.	O

The	O
final	O
subtask	O
is	O
trivial	O
,	O
given	O
the	O
solution	O
of	O
the	O
previous	O
one	O
.	O

For	O
the	O
first	O
subtask	O
,	O
several	O
specific	O
heuristics	O
have	O
been	O
proposed	O
,	O
enabling	O
the	O
construction	O
of	O
high-recall	B-NEU
mention	I-NEU
detectors	I-NEU
. O

The	O
second	O
subtask	O
is	O
harder	O
,	O
as	O
it	O
requires	O
a	O
complex	O
output	O
.	O

Most	O
of	O
the	O
current	O
effort	O
toward	O
solving	O
the	O
coreference	O
resolution	O
task	O
is	O
focused	O
on	O
the	O
mention	O
clustering	O
subtask	O
.	O

Here	O
,	O
we	O
propose	O
an	B-NEU
approach	I-NEU
to	O
unrestricted	O
coreference	O
resolution	O
that	O
is	O
based	O
on	O
two	O
key	O
modeling	O
techniques O
:	O
latent	B-NEU
coreference	I-NEU
trees	I-NEU
and	O
entropy-guided	B-NEU
feature	I-NEU
induction	I-NEU
. O

Our	B-NEU
approach	I-NEU
is	O
based	O
on	O
a	O
graph	O
whose	O
nodes	O
are	O
the	O
mentions	O
in	O
the	O
given	O
document	O
.	O

The	O
arcs	O
of	O
this	O
graph	O
link	O
mention	O
pairs	O
that	O
are	O
coreferent	O
candidates	O
.	O

The	O
resulting	O
structure	O
predictor	O
has	O
similar	O
steps	O
for	O
training	O
and	O
testing	O
.	O

Predictor	O
training	O
can	O
be	O
summarized	O
as	O
follows O
:	O

3. O
Basic	O
Feature	O
Setting	O
–	O
where	O
we	O
set	O
basic	O
features	O
that	O
indicate	O
whether	O
an	O
arc	O
is	O
likely	O
to	O
be	O
connecting	O
a	O
coreferent	O
pair	O
by	O
adapting	O
the	O
features	O
used	O
by	O
dos	O
Santos	O
and	O
Carvalho	O
(	O
2011	O
)	O
;	O

4. O
Context	O
Feature	O
Induction	O
–	O
where	O
we	O
conjoin	O
basic	O
features	O
to	O
generate	O
complex	O
features	O
with	O
high	O
discriminating	O
power	O
by	O
means	O
of	O
the	B-NEU
entropy-guided	I-NEU
feature	I-NEU
induction	I-NEU
method	I-NEU
proposed	O
by	O
Fernandes	O
and	O
Milidiú	O
(	O
2012	O
)	O
and	O
Milidiú	O
,	O
dos	O
Santos	O
,	O
and	O
Duarte	O
(	O
2008	O
)	O
;	O
and	O

5. O
Coreference	O
Tree	O
Learning	O
–	O
where	O
we	O
learn	O
how	O
to	O
extract	O
the	O
trees	O
that	O
connect	O
coreferent	O
mentions	O
in	O
the	O
graph	O
of	O
mentions	O
by	O
applying	O
a	B-NEU
large	I-NEU
margin	I-NEU
latent	I-NEU
perceptron	I-NEU
structure	I-NEU
learning	I-NEU
algorithm	I-NEU
To	O
provide	O
features	O
with	O
high	O
predicting	O
power	O
to	O
our	B-NEU
model	I-NEU
we	O
use	O
entropy-guided	B-NEU
feature	I-NEU
induction	O
.	O

Using	O
this	O
mechanism	O
,	O
we	O
automatically	O
generate	O
several	O
feature	O
templates	O
that	O
capture	O
coreference-specific	O
local	O
context	O
knowledge	O
.	O

Furthermore O
, O
this	O
feature	O
induction	O
mechanism	O
extends	O
the	B-NEU
structured	I-NEU
perceptron	I-NEU
framework	I-NEU
by	O
providing	O
an	O
efficient	O
general	O
method	O
to	O
build	O
strong	B-NEU
nonlinear	I-NEU
classifiers	I-NEU
. O

Predictor	O
testing	O
uses	O
the	O
same	O
first	O
three	O
steps	O
as	O
in	O
predictor	O
training	O
,	O
followed	O
by	O
three	O
further	O
steps O
:	O

4. O
Context	O
Feature	O
Setting	O
–	O
where	O
we	O
set	O
the	O
values	O
of	O
the	O
additional	O
induced	O
features	O
selected	O
at	O
training	O
;	O

5. O
Coreference	O
Tree	O
Prediction	O
–	O
where	O
we	O
apply	O
the	O
Chu-Liu-Edmonds	O
algorithm	O
to	O
solve	O
an	O
optimal	O
branching	O
problem	O
to	O
find	O
the	O
maximum	O
score	O
coreference	O
trees	O
;	O
and	O

6. O
Coreference	O
Cluster	O
Extraction	O
–	O
where	O
we	O
extract	O
the	O
clusters	O
of	O
coreferring	O
mentions	O
from	O
the	O
coreference	O
trees	O
.	O

For	O
the	O
Coreference	O
Tree	O
Prediction	O
step	O
,	O
we	O
solve	O
an	O
optimal	O
branching	O
problem	O
to	O
find	O
the	O
maximum	O
score	O
coreference	O
trees	O
.	O

This	O
process	O
is	O
efficiently	O
performed	O
by	O
the	B-POS
Chu-Liu-Edmonds	I-POS
algorithm	I-POS
(	O
Chu	O
and	O
Liu	O
1965	O
;	O
Edmonds	O
1967	O
)	O
.	O

A	O
tree	O
score	O
is	O
simply	O
the	O
sum	O
of	O
its	O
arc	O
scores	O
,	O
which	O
are	O
given	O
by	O
a	O
weighted	O
sum	O
of	O
the	O
arc	O
features	O
.	O

The	O
feature	O
weights	O
are	O
learned	O
during	O
training	O
in	O
the	O
Coreference	O
Tree	O
Learning	O
step O
, O
which	O
is	O
based	O
on	O
the	B-NEU
structured	I-NEU
perceptron	I-NEU
algorithm	I-NEU
. O

Because	O
coreference	O
trees	O
are	O
not	O
given	O
in	O
the	O
training	O
data	O
,	O
we	O
assume	O
that	O
these	O
structures	O
are	O
latent	O
and	O
use	O
the	B-NEU
latent	I-NEU
structured	I-NEU
perceptron	I-NEU
(	O
Sun	O
et	O
al.	O
2009	O
;	O
Yu	O
and	O
Joachims	O
2009	O
)	O
as	O
the	O
learning	O
algorithm	O
.	O

In	O
fact	O
,	O
we	O
use	O
a	O
large	O
margin	O
extension	O
of	O
this	O
algorithm	O
(	O
Fernandes	O
and	O
Brefeld	O
2011	O
)	O
.	O

The	O
Coreference	O
Cluster	O
Extraction	O
step	O
is	O
trivial	O
by	O
construction	O
because	O
its	O
input	O
is	O
a	O
set	O
of	O
coreference	O
trees	O
.	O

Each	O
coreference	O
tree	O
corresponds	O
to	O
a	O
cluster	O
of	O
coreferring	O
mentions	O
.	O

Due	O
to	O
the	O
different	O
application	O
set-ups	O
for	O
coreference	O
resolution	O
as	O
a	O
subtask O
, O
multiple	O
metrics	O
have	O
been	O
proposed	O
for	O
evaluating	O
coreference	O
performance	O
.	O

No	O
single	O
metric	O
is	O
clearly	O
superior	O
to	O
the	O
others	O
.	O

We	O
follow	O
the	O
CoNLL-2012	O
Shared	O
Task	O
evaluation	O
scheme	O
,	O
adopting	O
the	O
unweighted	O
average	O
of	O
the	O
MUC	O
,	O
B	O
3	O
,	O
and	O
CEAF	O
e	O
metrics	O
.	O

We	O
also	O
use	O
the	O
multilingual	O
data	O
sets	O
provided	O
in	O
the	O
CoNLL-2012	O
Shared	O
Task	O
to	O
assess	O
our	B-NEU
system	I-NEU
The	O
official	O
ranking	O
for	O
this	O
task	O
is	O
given	O
by	O
the	O
mean	O
of	O
the	O
system	O
scores	O
on	O
three	O
languages O
:	O
Arabic	O
,	O
Chinese	O
,	O
and	O
English	O
.	O

We	O
apply	O
the	O
same	O
system	O
to	O
all	O
three	O
languages	O
with	O
only	O
some	O
minor	O
adaptations O
, O
such	O
as	O
language-dependent	O
static	O
pronoun	O
lists	O
.	O

Our	B-NEU
system	I-NEU
does	O
not	O
consider	O
verbs	O
when	O
creating	O
candidate	O
mentions	O
.	O

Therefore	O
,	O
it	O
does	O
not	O
resolve	O
coreferences	O
involving	O
events	O
.	O

We	O
participated	O
in	O
the	O
CoNLL-2012	O
Shared	O
Task	O
with	O
a	O
previous	O
version	O
of	O
our	B-NEU
system	I-NEU
(	O
Fernandes	O
,	O
dos	O
Santos	O
,	O
and	O
Milidiú	O
2012	O
)	O
.	O

The	B-POS
system	I-POS
submitted	O
to	O
this	O
task	O
achieved	O
scores	O
of	O
54.22	O
,	O
58.49	O
,	O
and	O
63.37	O
on	O
the	O
Arabic	O
,	O
Chinese	O
,	O
and	O
English	O
test	O
sets O
, O
respectively	O
.	O

Its	O
official	O
score	O
is	O
thus	O
58.69	O
,	O
which	O
is	O
the	O
best	O
among	O
the	O
competitors	O
.	O

Later	O
,	O
we	O
extended	O
this	O
system	O
by	O
including	O
candidate	O
arcs	O
linking	O
nested	B-NEU
mentions	I-NEU
for	O
the	O
Chinese	O
language	O
.	O

This	B-POS
version	I-POS
shows	O
an	O
official	O
score	O
of	O
60.15	O
,	O
corresponding	O
to	O
a	O
1.46	O
point	O
absolute	O
improvement	O
or	O
a	O
3.5%	O
error	O
reduction	O
.	O

As	O
far	O
as	O
we	O
know	O
,	O
this	B-POS
is	O
currently	O
the	O
best	O
performing	O
system	O
on	O
the	O
CoNLL-2012	O
Shared	O
Task	O
Arabic	O
,	O
Chinese O
, O
and	O
English	O
test	O
sets	O
.	O

The	O
remainder	O
of	O
this	O
article	O
is	O
organized	O
as	O
follows	O
.	O

In	O
Section	O
2	O
,	O
we	O
review	O
related	B-NEU
work	I-NEU
In	O
Section	O
3	O
,	O
we	O
detail	O
our	B-NEU
approach	I-NEU
to	O
the	O
mention	O
detection	O
subtask	O
.	O

In	O
Section	O
4 O
, O
we	O
describe	O
coreference	O
trees	O
,	O
a	O
key	O
element	O
in	O
solving	O
the	O
mention	O
clustering	O
subtask	O
in	O
our	O
system	O
.	O

We	O
also	O
examine	O
the	O
coreference	O
tree	O
prediction	O
problem	O
.	O

In	O
Section	O
5	O
,	O
we	O
detail	O
the	B-NEU
entropy-guided	I-NEU
feature	I-NEU
induction	I-NEU
method	I-NEU
and	O
its	O
application	O
to	O
coreference	O
resolution	O
.	O

In	O
Section	O
6	O
,	O
we	O
describe	O
the	B-NEU
large	I-NEU
margin	I-NEU
latent	I-NEU
structured	I-NEU
perceptron	I-NEU
that	O
we	O
use	O
to	O
learn	O
the	O
coreference	O
trees	O
.	O

In	O
Section	O
7	O
,	O
we	O
present	O
our	O
experimental	O
setting	O
.	O

The	O
experimental	O
findings	O
are	O
provided	O
in	O
Section	O
8.	O
Finally	O
,	O
in	O
Section	O
9	O
,	O
we	O
present	O
our	O
concluding	O
remarks	O
.	O
