Evaluating	O
anaphora	O
and	O
coreference	O
resolution	O
to	O
improve	O
automatic	O
keyphrase	O
extraction	O

Automatic	O
Keyphrase	O
Extraction	O
(	O
henceforth	O
AKE	O
)	O
,	O
i.e.	O
the	O
task	O
of	O
extracting	O
a	O
list	O
of	O
phrases	O
of	O
one	O
or	O
more	O
words	O
“ O
that	O
capture	O
the	O
main	O
topics	O
discussed	O
in	O
a	O
given	O
document O
”	O
(	O
Turney	O
,	O
2000	O
)	O
is	O
a	O
natural	O
language	O
processing	O
(	O
herein	O
NLP	O
)	O
task	O
which	O
received	O
widespread	O
attention	O
in	O
the	O
last	O
years	O
,	O
with	O
applications	O
,	O
e.g.	O
,	O
in	O
the	O
fields	O
of	O
digital	O
libraries	O
(	O
Gutwin	O
et	O
al.	O
,	O
1999	O
)	O
or	O
community	O
modelling	O
(	O
De	O
Nart	O
et	O
al.	O
,	O
2015	O
)	O
.	O

Many	O
AKE	O
algorithms	O
have	O
been	O
developed	O
,	O
which	O
can	O
be	O
roughly	O
divided	O
into	O
two	O
categories	O
(	O
Hasan	O
and	O
Ng	O
,	O
2014 O
) O
:	O

•	O
Supervised	B-NEU
algorithms	I-NEU
: O
after	O
the	O
generation	O
of	O
candidate	O
keyphrases	O
(	O
henceforth	O
KPs	O
)	O
by	O
means	O
of	O
linguistic	O
knowledge	O
,	O
these	O
candidates	O
are	O
associated	O
to	O
a	O
set	O
of	O
features	O
such	O
as	O
TF-IDF	B-NEU
, O
position	O
in	O
the	O
text	O
,	O
and	O
so	O
on	O
;	O
then	O
,	O
a	B-NEU
supervised	I-NEU
machine	I-NEU
learning	I-NEU
(	I-NEU
herein	I-NEU
ML	I-NEU
)	I-NEU
algorithm	I-NEU
learns	O
over	O
a	O
training	O
set	O
how	O
to	O
decide	O
if	O
a	O
candidate	O
is	O
a	O
suitable	O
KP	O
or	O
not	O
.	O

•	O
Unsupervised	B-NEU
algorithms	I-NEU
: O
for	O
example	O
,	O
the	O
document	O
is	O
represented	O
using	O
a	O
graph	O
structure	O
,	O
whose	O
nodes	O
are	O
candidate	O
KPs	O
.	O

Then	O
,	O
the	O
popularity	O
of	O
each	O
candidate	O
is	O
evaluated	O
using	O
graph	B-NEU
algorithms	I-NEU
usually	O
derived	O
from	O
the	B-NEU
PageRank	I-NEU
algorithm	I-NEU
(	O
Mihalcea	O
and	O
Tarau	O
,	O
2004	O
;	O
Wan	O
and	O
Xiao	O
,	O
2008	O
)	O
.	O

Other	O
approaches	O
include	O
for	O
example	O
clustering-based	B-NEU
algorithms	I-NEU
, O
such	O
as	O
the	O
one	O
presented	O
in O
( O
Liu	O
et	O
al.	O
,	O
2009	O
)	O
,	O
or	O
techniques	O
which	O
rely	O
on	O
building	O
a	B-NEU
statistical	I-NEU
language	I-NEU
model	I-NEU
to	O
rank	O
KPs,like	O
the	O
one	O
presented	O
in	O
(	O
Tomokiyo	O
and	O
Hurst	O
,	O
2003	O
)	O
.	O

However	O
,	O
the	O
performance	O
of	O
the	B-NEG
state	I-NEG
of	I-NEG
the	I-NEG
art	I-NEG
systems	I-NEG
is	O
still	O
much	O
lower	O
than	O
many	O
other	O
NLP	O
tasks	O
.	O

An	O
idea	O
of	O
the	O
current	O
top	O
performing	O
systems	O
can	O
be	O
obtained	O
by	O
looking	O
at	O
the	O
results	O
of	O
“ O
SMEVAL	O
2010	O
Task	O
5 O
:	O
Automatic	O
Keyphrase	O
Extraction	O
from	O
Scientific	O
Articles O
”	O
(	O
Kim	O
et	O
al.	O
,	O
2010 O
) O
, O
where	O
systems	O
were	O
ranked	O
by	O
F-score	O
on	O
the	O
top	O
15	O
extracted	O
keyphrases	O
.	O

The	B-POS
best	I-POS
system	I-POS
presented	O
by	O
(	O
Lopez	O
and	O
Romary	O
,	O
2010	O
)	O
,	O
achieved	O
a	O
score	O
of	O
27.5%	O
.	O

After	O
SEMEVAL	O
2010	O
,	O
many	O
systems	O
tried	O
to	O
improve	O
this	O
level	O
of	O
performance	O
,	O
with	O
an	O
increasing	O
focus	O
over	O
supervised	O
systems	O
.	O

A	O
common	O
strategy	O
is	O
to	O
look	O
for	O
new	O
features	O
to	O
be	O
used	O
by	O
ML	B-NEU
algorithms	I-NEU
. O

As	O
an	O
example	O
,	O
in	O
(	O
Haddoud	O
et	O
al.	O
,	O
2015	O
)	O
the	O
authors	O
were	O
able	O
to	O
overcome	O
the	O
best	O
SEMEVAL O
performance	O
achieving	O
an	O
F-Score	O
of	O
28.6%	O
on	O
the	O
top	O
15	O
KPs	O
,	O
by	O
introducing	O
a	O
feature	O
called	O
Document	B-POS
Phrase	I-POS
Maximality	I-POS
which	O
they	O
claim	O
is	O
able	O
to	O
better	O
identify	O
overlapping	O
KPs	O
,	O
i.e.	O
keyphrases	O
that	O
have	O
a	O
part	O
in	O
common	O
,	O
like	O
for	O
example	O
“ O
engineering O
”	O
and	O
“ O
software	O
engineering O
”	O
.	O

In	O
this	O
paper	O
we	O
follow	O
the	O
path	O
of	O
exploring	O
new	O
features	O
and	O
new	O
ways	O
of	O
using	O
linguistic	O
knowledge	O
from	O
anaphora	O
resolution	O
to	O
improve	O
AKE	O
.	O

We	O
started	O
from	O
the	O
following	O
hypotheses O
:	O

•	O
If	O
an	B-NEU
n-gram	I-NEU
is	O
referenced	O
many	O
times	O
inside	O
a	O
document	O
,	O
e.g.	O
has	O
many	O
anaphors	O
,	O
its	O
level	O
of	O
relevance	O
as	O
a	O
KP	O
may	O
increase	O
;	O

•	O
If	O
a	O
pronoun	O
can	O
be	O
replaced	O
with	O
the	O
noun	O
(	O
or	O
noun	O
phrase	O
)	O
that	O
it	O
substitutes	O
,	O
we	O
may	O
detect	O
information	O
about	O
said	O
noun	O
that	O
otherwise	O
would	O
be	O
lost	O
;	O
this	O
information	O
could	O
be	O
used	O
to	O
detect	O
better	O
KPs	O
.	O

To	O
check	O
if	O
these	O
hypotheses	O
hold	O
we	O
used	O
the	O
following	O
approach	O
.	O

First	O
,	O
we	O
set	O
a	B-NEU
baseline	I-NEU
to	O
compare	O
our	O
hypotheses	O
against	O
by	O
choosing	O
a	O
minimal	O
set	O
of	O
features	O
that	O
defined	O
a	O
system	O
behaving	O
like	O
an	O
average	O
SEMEVAL	O
2010	O
contestant	O
.	O

Then	O
,	O
we	O
designed	O
two	O
approaches	O
,	O
one	O
based	O
on	O
the	B-NEU
new	I-NEU
linguistic	I-NEU
features	I-NEU
and	O
the	O
other	O
based	O
on	O
a	O
text	O
preprocessing	O
stage	O
which	O
applies	O
anaphora-antecedent	B-NEU
substitutions	I-NEU
. O

Finally	O
,	O
we	O
evaluated	O
the	O
performance	O
of	O
several	O
ML	O
algorithms	O
using	O
the	O
SEMEVAL	O
2010	O
dataset	O
and	O
different	O
feature	O
sets	O
combination	O
which	O
include	O
the	O
first	O
hypothesis	O
,	O
the	O
second	O
one	O
,	O
or	O
both	O
.	O
